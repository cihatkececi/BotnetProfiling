{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction\n",
    "\n",
    "Flow aggregation by a time window\n",
    "\n",
    "Generated features:\n",
    "* NumSrcPorts\n",
    "* NumDestAddr\n",
    "* NumDestPorts\n",
    "* NumFlows\n",
    "* NumBytes\n",
    "* NumPackets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(input_df):\n",
    "    # Take only the botnet part\n",
    "    df_botnet = input_df[input_df['Label'].str.contains(\"flow=From-Botnet\")]\n",
    "    df_botnet.loc[:, \"StartTime\"] = pd.to_datetime(df_botnet.StartTime, format='%Y/%m/%d %H:%M:%S.%f')\n",
    "    df_botnet.sort_values(by=['StartTime'], inplace=True)\n",
    "    df_botnet.reset_index(drop=True, inplace=True)\n",
    "#     df_botnet.head()\n",
    "    \n",
    "    \n",
    "    # Determine the time windows\n",
    "    time_windows = [0]\n",
    "    for i in range(1, len(df_botnet)):\n",
    "        # Find the optimal time window duration\n",
    "        if (df_botnet[\"StartTime\"][i] - df_botnet[\"StartTime\"][time_windows[-1]]).seconds > 30:\n",
    "            time_windows.append(i)\n",
    "\n",
    "    time_windows.append(len(df_botnet)) # Added it for easier indexing             \n",
    "    \n",
    "    \n",
    "    # Determined column keys\n",
    "    column_keys = [\"NumSrcPorts\", \"NumDestAddr\", \"NumDestPorts\", \"NumFlows\", \"NumBytes\", \"NumPackets\"]\n",
    "    gen_df = pd.DataFrame(None, columns=column_keys)\n",
    "\n",
    "    # Generate the features for each time window\n",
    "    for i in range(len(time_windows)-1):\n",
    "        current_df = df_botnet.iloc[time_windows[i]:time_windows[i+1],:]\n",
    "\n",
    "        group = current_df.groupby(\"SrcAddr\")\n",
    "\n",
    "        for address, addr_df in group:\n",
    "            # TODO: Optionally source ip address can be added\n",
    "#             print(address)\n",
    "\n",
    "            num_src_ports = len(addr_df.Sport.unique())\n",
    "\n",
    "            num_dest_addr = len(addr_df.DstAddr.unique())\n",
    "\n",
    "            num_dest_ports = len(addr_df.Dport.unique())\n",
    "\n",
    "            num_flows = time_windows[1] - time_windows[0]\n",
    "\n",
    "            # TODO: SrcBytes or TotBytes?\n",
    "            num_bytes = np.sum(addr_df.SrcBytes)\n",
    "\n",
    "            num_packets = np.sum(addr_df.TotPkts)\n",
    "\n",
    "            curr_gen_df = pd.DataFrame([[num_src_ports, num_dest_addr, num_dest_ports, num_flows, num_bytes, num_packets]], columns=column_keys)\n",
    "            gen_df = gen_df.append(curr_gen_df, ignore_index=True)\n",
    "            \n",
    "    return gen_df\n",
    "\n",
    "\n",
    "def extract_features_all(data_path):\n",
    "    scenario_list = os.listdir(data_path)\n",
    "#     print(scenario_list)\n",
    "\n",
    "    feat_list = []\n",
    "    \n",
    "    for scenario in scenario_list:\n",
    "        scenario_path = os.path.join(data_path, scenario)\n",
    "        \n",
    "        if os.path.isdir(scenario_path):\n",
    "            flow_file_path = glob.glob(os.path.join(scenario_path, \"*.binetflow\"))[0]\n",
    "            \n",
    "            # Extract features for the current scenario\n",
    "            input_df = pd.read_csv(flow_file_path)\n",
    "            scenario_features = extract_features(input_df)\n",
    "            \n",
    "            # Append scenario label\n",
    "            scenario_features.loc[:, \"Scenario\"] = int(scenario)\n",
    "            \n",
    "            feat_list.append(scenario_features)\n",
    "            \n",
    "    return pd.concat(feat_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cihat\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\Cihat\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NumSrcPorts</th>\n",
       "      <th>NumDestAddr</th>\n",
       "      <th>NumDestPorts</th>\n",
       "      <th>NumFlows</th>\n",
       "      <th>NumBytes</th>\n",
       "      <th>NumPackets</th>\n",
       "      <th>Scenario</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>780</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>15072</td>\n",
       "      <td>510</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>20881</td>\n",
       "      <td>659</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2771</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7261</td>\n",
       "      <td>183</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  NumSrcPorts NumDestAddr NumDestPorts NumFlows NumBytes NumPackets  Scenario\n",
       "0           2           2            2        3      780         11         1\n",
       "1          10           7            6        3    15072        510         1\n",
       "2          22          18            6        3    20881        659         1\n",
       "3          13          13            4        3     2771         47         1\n",
       "4          16          15            4        3     7261        183         1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_PATH = os.path.join(\"..\", \"ctu-13\")\n",
    "\n",
    "# start_time = time.time()\n",
    "gen_feat_df = extract_features_all(DATA_PATH)\n",
    "# print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "gen_feat_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate test and train sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Counts\n",
      "\n",
      "num\ttrain\ttest\ttotal\n",
      "------------------------------\n",
      "1\t355\t176\t531\n",
      "2\t262\t98\t360\n",
      "3\t1188\t489\t1677\n",
      "4\t93\t42\t135\n",
      "5\t25\t10\t35\n",
      "6\t139\t60\t199\n",
      "7\t2\t2\t4\n",
      "8\t828\t362\t1190\n",
      "9\t1858\t798\t2656\n",
      "10\t345\t132\t477\n",
      "11\t10\t4\t14\n",
      "12\t81\t44\t125\n",
      "13\t1263\t547\t1810\n",
      "------------------------------\n",
      "total:\t6449\t2764\t9213\n"
     ]
    }
   ],
   "source": [
    "# Generate test and train sets\n",
    "X = gen_feat_df.iloc[:, range(0, 6)].values\n",
    "y = gen_feat_df.iloc[:, 6].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .3, random_state=25)\n",
    "\n",
    "# Feature Counts\n",
    "print(\"Feature Counts\\n\")\n",
    "print(\"num\\ttrain\\ttest\\ttotal\")\n",
    "print(\"-\" * 30)\n",
    "for i in range(1, 14):\n",
    "    print(\"{0}\\t{1}\\t{2}\\t{3}\".format(i, np.count_nonzero(y_train==i), np.count_nonzero(y_test==i), np.count_nonzero(y==i)))\n",
    "print(\"-\" * 30)\n",
    "print(\"total:\\t{0}\\t{1}\\t{2}\".format(len(y_train), len(y_test), len(y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results():\n",
    "    print(\"\\nAccuracy:\")\n",
    "    print(metrics.accuracy_score(y_test, y_pred))\n",
    "    \n",
    "    print(\"\\nClassification report:\")\n",
    "    print(metrics.classification_report(y_test, y_pred))\n",
    "    \n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_regression = LogisticRegression()\n",
    "\n",
    "# Train the classifier\n",
    "log_regression.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = log_regression.predict(X_test)\n",
    "\n",
    "print_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN\n",
    "Tries for different k values and prints the metrics for the k value with the best accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_vals = []\n",
    "k_vals = []\n",
    "pred_vals = []\n",
    "\n",
    "for i in range(20):\n",
    "    k = 2*i+1\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = knn.predict(X_test)\n",
    "    \n",
    "    acc_vals.append(metrics.accuracy_score(y_test, y_pred))\n",
    "    k_vals.append(k)\n",
    "    pred_vals.append(y_pred)\n",
    "\n",
    "# print_results()\n",
    "plt.plot(k_vals, acc_vals)\n",
    "plt.title(\"Accuracy vs. k values\")\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot the results for best k value\n",
    "i_max_acc = acc_vals.index(max(acc_vals))\n",
    "print(\"Results for k={0}\".format(2*i_max_acc+1))\n",
    "\n",
    "y_pred = pred_vals[i_max_acc]\n",
    "print_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10-fold KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=k)\n",
    "scores = cross_val_score(knn, X, y, cv=10)\n",
    "\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10-fold Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression()\n",
    "scores = cross_val_score(log_reg, X, y, cv=10)\n",
    "\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_clf = svm.SVC(kernel='rbf', C=1)\n",
    "\n",
    "svm_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = svm_clf.predict(X_test)\n",
    "\n",
    "print_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy:\n",
      "0.951519536903039\n",
      "\n",
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.78      0.79      0.78       176\n",
      "          2       0.66      0.62      0.64        98\n",
      "          3       0.99      1.00      0.99       489\n",
      "          4       0.95      0.88      0.91        42\n",
      "          5       0.50      0.40      0.44        10\n",
      "          6       0.96      0.92      0.94        60\n",
      "          7       0.00      0.00      0.00         2\n",
      "          8       0.99      0.99      0.99       362\n",
      "          9       0.99      1.00      0.99       798\n",
      "         10       0.95      0.95      0.95       132\n",
      "         11       1.00      0.75      0.86         4\n",
      "         12       1.00      1.00      1.00        44\n",
      "         13       0.94      0.95      0.94       547\n",
      "\n",
      "avg / total       0.95      0.95      0.95      2764\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[139  20   0   0   2   0   0   0   0   0   0   0  15]\n",
      " [ 25  61   0   0   0   0   0   0   0   0   0   0  12]\n",
      " [  0   0 487   2   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   5  37   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   4   0   0   0   0   0   0   0   6]\n",
      " [  0   0   0   0   0  55   0   5   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   2   0   0   0]\n",
      " [  0   0   0   0   0   2   0 360   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 795   3   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   6 126   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   1   3   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  44   0]\n",
      " [ 15  11   0   0   2   0   0   0   0   0   0   0 519]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cihat\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "rand_forest_clf = RandomForestClassifier(n_estimators=10)\n",
    "\n",
    "rand_forest_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rand_forest_clf.predict(X_test)\n",
    "\n",
    "print_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10-fold Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cihat\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:605: Warning: The least populated class in y has only 4 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.93 (+/- 0.10)\n"
     ]
    }
   ],
   "source": [
    "rand_forest_clf = RandomForestClassifier(n_estimators=10)\n",
    "\n",
    "scores = cross_val_score(rand_forest_clf, X, y, cv=10)\n",
    "\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
